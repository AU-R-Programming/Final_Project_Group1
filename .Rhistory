# Print confusion matrix metrics
print(metrics)
adult <- read.csv("C:/Users/sarah/Downloads/adult.csv", sep=";")
View(adult)
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
adult_data <- read.csv("adult.csv")
View(adult)
# Load all package functions for testing
devtools::load_all()
setwd("C:/Users/sarah/Downloads")
adult_data <- read.csv("adult.csv")
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
y
# Use columns 1 to 12 as features
X <- model.matrix(~., data = adult_data[, 1:4])  # Select columns 1 to 12 as features
logistic_regression <- function(X, y, ridge_penalty = 1e-5) {
# Regularized initial values for stability
beta_init <- solve(t(X) %*% X + diag(ridge_penalty, ncol(X)), t(X) %*% y)
# Log-likelihood function
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X %*% beta))  # Predicted probabilities
epsilon <- 1e-8                 # Small constant to prevent log(0)
p <- pmax(pmin(p, 1 - epsilon), epsilon)
-sum(y * log(p) + (1 - y) * log(1 - p))
}
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
}
bootstrap_ci <- function(X, y, n_boot = 20, alpha = 0.05) {
beta_estimates <- replicate(n_boot, {
idx <- sample(1:nrow(X), replace = TRUE)
logistic_regression(X[idx, ], y[idx])
})
lower <- apply(beta_estimates, 1, quantile, probs = alpha / 2)
upper <- apply(beta_estimates, 1, quantile, probs = 1 - alpha / 2)
ci <- cbind(lower, upper)
return(ci)
}
evaluate_model <- function(y_true, y_pred, cutoff = 0.5) {
y_class <- ifelse(y_pred > cutoff, 1, 0)
tp <- sum(y_class == 1 & y_true == 1)
fp <- sum(y_class == 1 & y_true == 0)
fn <- sum(y_class == 0 & y_true == 1)
tn <- sum(y_class == 0 & y_true == 0)
prevalence <- mean(y_true)
accuracy <- (tp + tn) / length(y_true)
sensitivity <- tp / (tp + fn)
specificity <- tn / (tn + fp)
false_discovery_rate <- fp / (fp + tp)
diagnostic_odds_ratio <- (tp / fn) / (fp / tn)
confusion_matrix <- matrix(c(tp, fn, fp, tn), nrow = 2,
dimnames = list(Predicted = c("Positive", "Negative"),
True = c("Positive", "Negative")))
metrics <- list(
ConfusionMatrix = confusion_matrix,
Prevalence = prevalence,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
FDR = false_discovery_rate,
DOR = diagnostic_odds_ratio
)
return(metrics)
}
devtools::load_all()
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
# Use columns 1 to 12 as features
X <- model.matrix(~., data = adult_data[, 1:4])  # Select columns 1 to 12 as features
features <- adult[, c("age", "education")]
outcome <- adult$income  # Assuming 'income' is the binary response variable
knitr::opts_chunk$set(echo = TRUE)
expenses <- read.csv("expenses.csv")
head(expenses)
n <- nrow(expenses)
p <- ncol(expenses)
expenses[] <- lapply(expenses, function(x) if (is.character(x)) as.factor(x) else x)
formula <- ~ . # this specifies how to model the data, tells it to include all the columns
design_matrix <- model.matrix(formula, data = expenses)
head(design_matrix)
dim(design_matrix)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
# Test logistic regression function
beta <- logistic_regression(X, y)
print(beta)
# Test bootstrap confidence intervals
ci <- bootstrap_ci(X, y)
print(ci)
# Test model evaluation
predictions <- 1 / (1 + exp(-X %*% beta))
metrics <- evaluate_model(y, predictions)
print(metrics)
beta_init <- solve(t(X) %*% X + diag(ridge_penalty, ncol(X)), t(X) %*% y)
# Regularized initial values for stability
beta_init <- solve(t(X) %*% X + diag(1e-5, ncol(X)), t(X) %*% y)
beta_init
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
# Log-likelihood function
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X %*% beta))  # Predicted probabilities
epsilon <- 1e-8                 # Small constant to prevent log(0)
p <- pmax(pmin(p, 1 - epsilon), epsilon)
-sum(y * log(p) + (1 - y) * log(1 - p))
}
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
opt$par
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
opt$par
setwd("~/GitHub/Final_Project_Group1")
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "L-BFGS-B"  # optimization method
)
}
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
# loss_func <- function(beta, X, y) {
#   p <- 1 / (1 + exp(-X %*% beta))
#   sum(-y * log(p) - (1 - y) * log(1 - p))
# }
# test loss
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
p <- pmin(pmax(p, 1e-15), 1 - 1e-15)  # Clip probabilities
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "L-BFGS-B"  # optimization method
)
}
# calculate initial beta
beta_init <- initial_beta(X, y)
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# Predict probabilities and calculate metrics
y_pred <- 1 / (1 + exp(-X %*% beta_opt_func))  # use design matrix with intercept
# Calculate metrics
metrics <- confusion_metrics(y, y_pred, cutoff = 0.5)
# Print confusion matrix metrics
print(metrics)
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# test loss
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
p <- pmin(pmax(p, 1e-15), 1 - 1e-15)  # Clip probabilities
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
library(devtools)
devtools::document()
?bootstrap_ci
knitr::opts_chunk$set(echo = TRUE)
expenses <- read.csv("expenses.csv")
head(expenses)
n <- nrow(expenses)
p <- ncol(expenses)
expenses[] <- lapply(expenses, function(x) if (is.character(x)) as.factor(x) else x)
formula <- ~ . # this specifies how to model the data, tells it to include all the columns
design_matrix <- model.matrix(formula, data = expenses)
head(design_matrix)
dim(design_matrix)
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- beta_opt_func(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- suppressMessages(suppressWarnings(beta_opt_func(X_boot, y_boot)))
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- suppressMessages(suppressWarnings(opt_beta_est(X_boot, y_boot)))
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
#cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Combine confidence intervals into a matrix and return
ci <- cbind(Lower_CI = ci_lower, Upper_CI = ci_upper)
return(ci)  # Return only the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
# Predict probabilities and calculate metrics
y_pred <- 1 / (1 + exp(-X %*% beta_opt_func))  # use design matrix with intercept
# Calculate metrics
metrics <- confusion_metrics(y, y_pred, cutoff = 0.5)
# Print confusion matrix metrics
print(metrics)
confusion_metrics <- function(y_true, y_pred, cutoff = 0.5) {
y_pred_1 <- ifelse(y_pred > cutoff, 1, 0)
TP <- sum(y_true == 1 & y_pred_1 == 1)
TN <- sum(y_true == 0 & y_pred_1 == 0)
FP <- sum(y_true == 0 & y_pred_1 == 1)
FN <- sum(y_true == 1 & y_pred_1 == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- ifelse((TP + FN) > 0, TP / (TP + FN), NA)
specificity <- ifelse((TN + FP) > 0, TN / (TN + FP), NA)
FDR <- ifelse((FP + TP) > 0, FP / (FP + TP), NA)
# Avoid NaN for DOR
if (FN == 0 || FP == 0 || TN == 0) {
DOR <- NA
} else {
DOR <- (TP / FN) / (FP / TN)
}
return(list(
prevalence = prevalence,
accuracy = accuracy,
sensitivity = sensitivity,
specificity = specificity,
FDR = FDR,
DOR = DOR
))
}
# Predict probabilities and calculate metrics
y_pred <- 1 / (1 + exp(-X %*% beta_opt_func))  # use design matrix with intercept
# Calculate metrics
metrics <- confusion_metrics(y, y_pred, cutoff = 0.5)
# Print confusion matrix metrics
print(metrics)
table(y_true)
table(y)
table(y_pred)
summary(y_pred)
set.seed(42)  # for reproducibility
n <- 100   # number of observations
p <- 3     # number of predictors
beta_true <- c(1.25, 0.5, -1, 0.75)  # true coefficients
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # predictor matrix
design <- cbind(1, X)                           # add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # probabilities
y <- rbinom(n, size = 1, prob = p_i)            # response variable
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
beta_opt
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
View(X)
View(design)
X <- design <- cbind(1, X)                           # add intercept column
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
beta_opt
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20)
# Calculate metrics
metrics <- confusion_metrics(y, y_pred)
# Confusion matrix metrics
confusion_metrics <- function(y_true, y_pred) {
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
FDR <- FP / (FP + TP)
DOR <- (TP / FN) / (FP / TN)
return(list(prevalence = prevalence, accuracy = accuracy, sensitivity = sensitivity,
specificity = specificity, FDR = FDR, DOR = DOR))
}
p_hat <- 1 / (1 + exp(-X %*% beta_opt))  # use design matrix with intercept
y_pred <- ifelse(p_hat > 0.5, 1, 0)  # classify predictions
# Calculate metrics
metrics <- confusion_metrics(y, y_pred)
# Print confusion matrix metrics
print(metrics)
