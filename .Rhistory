p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
# putting above functions together
opt_beta_est <- function(X, y){
X <- cbind(rep(1, n), X)
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", result$par, "\n")
optimal_beta_est <- result$par
return(optimal_beta_est)
}
# testing code
set.seed(42)  # for reproducibility
n <- 100   # Number of observations
p <- 3     # Number of predictors
beta_true <- c(1.25, 0.5, -1, 0.75)  # true coefficients, first term is intercept
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
design <- cbind(rep(1, n), X)
p_i <- 1 / (1 + exp(-design %*% beta_true)) # probability for y generation
y <- rbinom(n, size = 1, prob = p_i)
# testing final function
opt_beta_est(X = X, y = y)
# test other code
initial_beta <- function(X, y) {
solve(t(X) %*% X) %*% t(X) %*% y
}
# Loss function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# Beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"
)
}
# Function to combine all steps and estimate beta
opt_beta_est <- function(X, y) {
# Add intercept column
X <- cbind(1, X)
# Initial beta using least squares
beta_initial <- initial_beta(X = X, y = y)
# Optimize beta using loss function
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
# Print results
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# Test code
set.seed(42)  # for reproducibility
n <- 100      # Number of observations
p <- 3        # Number of predictors
# True beta coefficients, including intercept
beta_true <- c(1.25, 0.5, -1, 0.75)
# Generate data
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # Predictor matrix
design <- cbind(1, X)                           # Add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # Probabilities
y <- rbinom(n, size = 1, prob = p_i)            # Response variable
# Estimate beta using function
estimated_beta <- opt_beta_est(X = X, y = y)
# Compare with true beta
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", estimated_beta, "\n")
opt_beta_est(X = X, y = y)
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
# Function to combine all steps and estimate beta
opt_beta_est <- function(X, y) {
# Add intercept column
X <- cbind(rep(1,n), X)
# Initial beta using least squares
beta_initial <- initial_beta(X = X, y = y)
# Optimize beta using loss function
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
# Print results
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
set.seed(42)  # for reproducibility
n <- 100      # Number of observations
p <- 3        # Number of predictors
# True beta coefficients, including intercept
beta_true <- c(1.25, 0.5, -1, 0.75)
# Generate data
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # Predictor matrix
design <- cbind(1, X)                           # Add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # Probabilities
y <- rbinom(n, size = 1, prob = p_i)            # Response variable
# Estimate beta using function
estimated_beta <- opt_beta_est(X = X, y = y)
# Compare with true beta
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", estimated_beta, "\n")
opt_beta_est(X = X, y = y)
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
# putting above functions together
opt_beta_est <- function(X, y){
X <- cbind(rep(1, n), X)
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# testing code
set.seed(42)  # for reproducibility
n <- 100   # number of observations
p <- 3     # number of predictors
beta_true <- c(1.25, 0.5, -1, 0.75)  # true coefficients
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # predictor matrix
design <- cbind(1, X)                           # add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # probabilities
y <- rbinom(n, size = 1, prob = p_i)            # response variable
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# calculate initial beta
beta_init <- initial_beta(X, y)
# estimate beta using optimization
result <- estimate_beta(X, y, beta_init)
# display results compared to true values
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", result$par, "\n")
cat("Estimated beta:", beta_opt, "\n")
# display results compared to true values
cat("True beta:", beta_true, "\n")
library(roxygen2)
setwd("C:/Users/sarah/Documents/GitHub/Final_Project_Group1")
library(devtools)
devtools::document()
devtools::document()
# putting above functions together
opt_beta_est <- function(X, y){
n <- nrow(X)  # calculate the number of rows in X
X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
# putting above functions together
opt_beta_est <- function(X, y){
n <- nrow(X)  # calculate the number of rows in X
X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
setwd("C:/Users/sarah/Documents/GitHub/Final_Project_Group1")
devtools::document()
rlang::last_trace()
codetools::findGlobals(asNamespace("Final_Project_Group1"))
codetools::findGlobals(asNamespace("opt_beta_est.R"))
devtools::load_all(quiet = FALSE)
devtools::document()
rlang::last_trace()
devtools::document()
# Confusion matrix metrics
confusion_metrics <- function(y_true, y_pred) {
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
FDR <- FP / (FP + TP)
DOR <- (TP / FN) / (FP / TN)
return(list(prevalence = prevalence, accuracy = accuracy, sensitivity = sensitivity,
specificity = specificity, FDR = FDR, DOR = DOR))
}
# Predict probabilities and calculate metrics
X_design <- cbind(1, X)  # add intercept column
p_hat <- 1 / (1 + exp(-X_design %*% beta_opt))  # use design matrix with intercept
y_pred <- ifelse(p_hat > 0.5, 1, 0)  # classify predictions
devtools::document()
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
#'
#' @examples
#' n <- 100
#' p <- 3
#' X <- matrix(rnorm(n * p), nrow = n, ncol = p)
#' design <- cbind(1, X)
#' p_i <- 1 / (1 + exp(-design %*% beta_true))
#' y <- rbinom(n, size = 1, prob = p_i)
#' beta_opt <- opt_beta_est(X = X, y = y)
#' print(beta_opt)
opt_beta_est <- function(X, y){
X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# testing code
set.seed(42)  # for reproducibility
n <- 100   # number of observations
p <- 3     # number of predictors
beta_true <- c(1.25, 0.5, -1, 0.75)  # true coefficients
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # predictor matrix
design <- cbind(1, X)                           # add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # probabilities
y <- rbinom(n, size = 1, prob = p_i)            # response variable
# calculate initial beta
beta_init <- initial_beta(X, y)
# estimate beta using optimization
result <- estimate_beta(X, y, beta_init)
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# display results compared to true values
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", beta_opt, "\n")
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- beta_opt_func(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
# Confusion matrix metrics
confusion_metrics <- function(y_true, y_pred) {
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
FDR <- FP / (FP + TP)
DOR <- (TP / FN) / (FP / TN)
return(list(prevalence = prevalence, accuracy = accuracy, sensitivity = sensitivity,
specificity = specificity, FDR = FDR, DOR = DOR))
}
# Predict probabilities and calculate metrics
X_design <- cbind(1, X)  # add intercept column
p_hat <- 1 / (1 + exp(-X_design %*% beta_opt))  # use design matrix with intercept
y_pred <- ifelse(p_hat > 0.5, 1, 0)  # classify predictions
# Calculate metrics
metrics <- confusion_metrics(y, y_pred)
# Print confusion matrix metrics
print(metrics)
devtools::document()
?opt_beta_est
devtools:document()
devtools::document()
?opt_beta_est
expenses <- read.csv("~/GitHub/Final_Project_Group1/expenses.csv")
View(expenses)
```r
```r
knitr::opts_chunk$set(echo = TRUE)
data(expenses)
library(expenses)
head(expenses)
n <- nrow(expenses)
head(expenses)
n <- nrow(expenses)
p <- ncol(expenses)
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# testing code
set.seed(42)  # for reproducibility
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # predictor matrix
design <- cbind(1, X)                           # add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # probabilities
y <- rbinom(n, size = 1, prob = p_i)            # response variable
# calculate initial beta
beta_init <- initial_beta(X, y)
# estimate beta using optimization
result <- estimate_beta(X, y, beta_init)
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# display results compared to true values
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", beta_opt, "\n")
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
# testing code
set.seed(42)  # for reproducibility
n <- 100   # number of observations
p <- 3     # number of predictors
beta_true <- c(1.25, 0.5, -1, 0.75)  # true coefficients
X <- matrix(rnorm(n * p), nrow = n, ncol = p)   # predictor matrix
design <- cbind(1, X)                           # add intercept column
p_i <- 1 / (1 + exp(-design %*% beta_true))     # probabilities
y <- rbinom(n, size = 1, prob = p_i)            # response variable
# calculate initial beta
beta_init <- initial_beta(X, y)
# estimate beta using optimization
result <- estimate_beta(X, y, beta_init)
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# display results compared to true values
cat("True beta:", beta_true, "\n")
cat("Estimated beta:", beta_opt, "\n")
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- beta_opt_func(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
# Confusion matrix metrics
confusion_metrics <- function(y_true, y_pred) {
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
FDR <- FP / (FP + TP)
DOR <- (TP / FN) / (FP / TN)
return(list(prevalence = prevalence, accuracy = accuracy, sensitivity = sensitivity,
specificity = specificity, FDR = FDR, DOR = DOR))
}
# Predict probabilities and calculate metrics
X_design <- cbind(1, X)  # add intercept column
p_hat <- 1 / (1 + exp(-X_design %*% beta_opt))  # use design matrix with intercept
y_pred <- ifelse(p_hat > 0.5, 1, 0)  # classify predictions
# Calculate metrics
metrics <- confusion_metrics(y, y_pred)
# Print confusion matrix metrics
print(metrics)
n <- nrow(expenses)
p <- ncol(expenses)
View(expenses)
opt_beta_est(X = expenses[, 1:6], y = expenses$charges)
str(expenses)
expenses[] <- lapply(expenses, function(col) {
if (is.character(col)) {
as.numeric(factor(col))
} else {
col
}
})
str(expenses)
opt_beta_est(X = expenses[, 1:6], y = expenses$charges)
t(expenses[, 1:6])
opt_beta_est(X = expenses[, 1:6], y = expenses$charges)
sapply(expenses[, 1:6], class)
