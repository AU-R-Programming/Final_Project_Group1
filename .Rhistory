#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
nrow(design_matrix)
ncol(design_matrix)
head(design_matrix[,10])
head(design_matrix[10,])
opt_beta_est(X = design_matrix[, 1:9], y = design_matrix[, 10])
kappa(t(X) %*% X)
kappa(t(design_matrix) %*% design_matrix)
design_matrix[, 1:9]
y = design_matrix[, 10]
y
X = design_matrix[, 1:9]
# calculate initial beta
beta_init <- initial_beta(X, y)
beta_init
estimate_beta(X, y, beta_init)
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_init = beta_initial)
beta_init
beta_opt <- estimate_beta(X = X, y = y, beta_init = as.vector(beta_initial))
beta_opt <- estimate_beta(X = X, y = y, beta_init = rep(0, 9))
head(design_matrix)
head(design_matrix[,3])
opt_beta_est(X = design_matrix[, -3], y = design_matrix[, 3])
X = design_matrix[, -3]
y = design_matrix[, 3]
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_initial
beta_opt <- estimate_beta(X = X, y = y, beta_init = as.vector(beta_initial))
y
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_init,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
beta_opt <- estimate_beta(X = X, y = y, beta_init = as.vector(beta_initial))
# beta optimization function
estimate_beta <- function(X, y, beta_init) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
beta_opt <- estimate_beta(X = X, y = y, beta_init = as.vector(beta_initial))
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
initial_beta
beta_initial
any(!is.finite(beta_initial))
any(is.na(X))
any(!is.finite(X))
any(is.na(y))
any(!is.finite(y))
# test loss
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
p <- pmin(pmax(p, 1e-15), 1 - 1e-15)  # Clip probabilities
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
rep(1, n), X) # adding intercept
beta_initial
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
beta_opt
opt_beta_est(X = design_matrix[, -3], y = design_matrix[, 3])
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- beta_opt_func(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
bootstrap_ci(X = design_matrix[, -3], y = design_matrix[, 3], beta_opt_func = beta_opt_func, alpha = 0.05, n_bootstrap = 20)
bootstrap_ci(X = design_matrix[, -3], y = design_matrix[, 3], beta_opt_func = opt_beta_est((X = design_matrix[, -3], y = design_matrix[, 3]), alpha = 0.05, n_bootstrap = 20)
bootstrap_ci(
X = design_matrix[, -3],
y = design_matrix[, 3],
beta_opt_func = opt_beta_est(
X = design_matrix[, -3],
y = design_matrix[, 3]
),
alpha = 0.05,
n_bootstrap = 20
)
bootstrap_ci <- function(X, y, beta_opt_func, alpha = 0.05, n_bootstrap = 20) {
n <- nrow(X)                # Number of observations
p <- ncol(X)                # Number of predictors
bootstrap_betas <- matrix(0, nrow = n_bootstrap, ncol = p)  # Matrix to store bootstrap beta estimates
for (i in 1:n_bootstrap) {
# Resample data with replacement
sample_indices <- sample(1:n, size = n, replace = TRUE)  # Bootstrap sample indices
X_boot <- X[sample_indices, ]                           # Bootstrap predictors
y_boot <- y[sample_indices]                             # Bootstrap response
# Estimate beta for the bootstrap sample using the provided beta optimization function
bootstrap_betas[i, ] <- opt_beta_est(X_boot, y_boot)   # Store the estimated beta
}
# Compute confidence intervals
ci_lower <- apply(bootstrap_betas, 2, function(b) quantile(b, alpha / 2))  # Lower quantile
ci_upper <- apply(bootstrap_betas, 2, function(b) quantile(b, 1 - alpha / 2))  # Upper quantile
# Create a data frame for the confidence intervals
ci <- data.frame(
Coefficient = 1:p,
Lower_CI = ci_lower,
Upper_CI = ci_upper
)
return(ci)  # Return the confidence intervals
}
bootstrap_ci(
X = design_matrix[, -3],
y = design_matrix[, 3],
beta_opt_func = opt_beta_est(
X = design_matrix[, -3],
y = design_matrix[, 3]
),
alpha = 0.05,
n_bootstrap = 20
)
confusion_metrics <- function(y_true, y_pred) {
TP <- sum(y_true == 1 & y_pred == 1)
TN <- sum(y_true == 0 & y_pred == 0)
FP <- sum(y_true == 0 & y_pred == 1)
FN <- sum(y_true == 1 & y_pred == 0)
prevalence <- mean(y_true)
accuracy <- (TP + TN) / length(y_true)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
FDR <- FP / (FP + TP)
DOR <- (TP / FN) / (FP / TN)
return(list(
prevalence = prevalence,
accuracy = accuracy,
sensitivity = sensitivity,
specificity = specificity,
FDR = FDR,
DOR = DOR
))
}
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
install_github("AU-R-Programming/Final_Project_Group1")
library(Optimization)
X <- design_matrix[, -3]
expenses <- read.csv("expenses.csv")
head(expenses)
n <- nrow(expenses)
p <- ncol(expenses)
expenses[] <- lapply(expenses, function(x) if (is.character(x)) as.factor(x) else x)
formula <- ~ . # this specifies how to model the data, tells it to include all the columns
design_matrix <- model.matrix(formula, data = expenses)
head(design_matrix)
dim(design_matrix)
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
dim(beta_opt_func)
length(beta_opt_func)
dim(beta_opt_func)
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_initial
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_initial
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
test_beta <- rep(0, ncol(X))  # A test beta vector
loss_func(beta = test_beta, X = X, y = y)  # Does it return a valid numeric value?
print(beta_initial)
initial_loss <- loss_func(beta = beta_initial, X = X, y = y)
print(initial_loss)
# Calculate initial beta values, least squares = (XtX)^-1 %*% XTy
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
# test loss
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
p <- pmin(pmax(p, 1e-10), 1 - 1e-10)  # Clip probabilities
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "BFGS"  # optimization method
)
}
opt_beta_est <- function(X, y){
#n <- nrow(X)  # calculate the number of rows in X
#X <- cbind(rep(1, n), X) # adding intercept
beta_initial <- initial_beta(X = X, y = y)
beta_opt <- estimate_beta(X = X, y = y, beta_initial = as.vector(beta_initial))
cat("Estimated beta:", beta_opt$par, "\n")
return(beta_opt$par)
}
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
bootstrap_ci(X, y, beta_opt_func, alpha = 0.05,n_bootstrap = 20)
# Predict probabilities and calculate metrics
y_pred <- 1 / (1 + exp(-X %*% beta_opt_func))  # use design matrix with intercept
# Calculate metrics
metrics <- confusion_metrics(y, y_pred, cutoff = 0.5)
# Print confusion matrix metrics
print(metrics)
adult <- read.csv("C:/Users/sarah/Downloads/adult.csv", sep=";")
View(adult)
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
adult_data <- read.csv("adult.csv")
View(adult)
# Load all package functions for testing
devtools::load_all()
setwd("C:/Users/sarah/Downloads")
adult_data <- read.csv("adult.csv")
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
y
# Use columns 1 to 12 as features
X <- model.matrix(~., data = adult_data[, 1:4])  # Select columns 1 to 12 as features
logistic_regression <- function(X, y, ridge_penalty = 1e-5) {
# Regularized initial values for stability
beta_init <- solve(t(X) %*% X + diag(ridge_penalty, ncol(X)), t(X) %*% y)
# Log-likelihood function
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X %*% beta))  # Predicted probabilities
epsilon <- 1e-8                 # Small constant to prevent log(0)
p <- pmax(pmin(p, 1 - epsilon), epsilon)
-sum(y * log(p) + (1 - y) * log(1 - p))
}
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
}
bootstrap_ci <- function(X, y, n_boot = 20, alpha = 0.05) {
beta_estimates <- replicate(n_boot, {
idx <- sample(1:nrow(X), replace = TRUE)
logistic_regression(X[idx, ], y[idx])
})
lower <- apply(beta_estimates, 1, quantile, probs = alpha / 2)
upper <- apply(beta_estimates, 1, quantile, probs = 1 - alpha / 2)
ci <- cbind(lower, upper)
return(ci)
}
evaluate_model <- function(y_true, y_pred, cutoff = 0.5) {
y_class <- ifelse(y_pred > cutoff, 1, 0)
tp <- sum(y_class == 1 & y_true == 1)
fp <- sum(y_class == 1 & y_true == 0)
fn <- sum(y_class == 0 & y_true == 1)
tn <- sum(y_class == 0 & y_true == 0)
prevalence <- mean(y_true)
accuracy <- (tp + tn) / length(y_true)
sensitivity <- tp / (tp + fn)
specificity <- tn / (tn + fp)
false_discovery_rate <- fp / (fp + tp)
diagnostic_odds_ratio <- (tp / fn) / (fp / tn)
confusion_matrix <- matrix(c(tp, fn, fp, tn), nrow = 2,
dimnames = list(Predicted = c("Positive", "Negative"),
True = c("Positive", "Negative")))
metrics <- list(
ConfusionMatrix = confusion_matrix,
Prevalence = prevalence,
Accuracy = accuracy,
Sensitivity = sensitivity,
Specificity = specificity,
FDR = false_discovery_rate,
DOR = diagnostic_odds_ratio
)
return(metrics)
}
devtools::load_all()
# Ensure the response variable is 'income'
y <- adult_data$income  # Response variable
# Use columns 1 to 12 as features
X <- model.matrix(~., data = adult_data[, 1:4])  # Select columns 1 to 12 as features
features <- adult[, c("age", "education")]
outcome <- adult$income  # Assuming 'income' is the binary response variable
knitr::opts_chunk$set(echo = TRUE)
expenses <- read.csv("expenses.csv")
head(expenses)
n <- nrow(expenses)
p <- ncol(expenses)
expenses[] <- lapply(expenses, function(x) if (is.character(x)) as.factor(x) else x)
formula <- ~ . # this specifies how to model the data, tells it to include all the columns
design_matrix <- model.matrix(formula, data = expenses)
head(design_matrix)
dim(design_matrix)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
# Test logistic regression function
beta <- logistic_regression(X, y)
print(beta)
# Test bootstrap confidence intervals
ci <- bootstrap_ci(X, y)
print(ci)
# Test model evaluation
predictions <- 1 / (1 + exp(-X %*% beta))
metrics <- evaluate_model(y, predictions)
print(metrics)
beta_init <- solve(t(X) %*% X + diag(ridge_penalty, ncol(X)), t(X) %*% y)
# Regularized initial values for stability
beta_init <- solve(t(X) %*% X + diag(1e-5, ncol(X)), t(X) %*% y)
beta_init
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
# Log-likelihood function
log_likelihood <- function(beta) {
p <- 1 / (1 + exp(-X %*% beta))  # Predicted probabilities
epsilon <- 1e-8                 # Small constant to prevent log(0)
p <- pmax(pmin(p, 1 - epsilon), epsilon)
-sum(y * log(p) + (1 - y) * log(1 - p))
}
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
opt$par
library(Optimization)
X <- design_matrix[, -3]
y <- design_matrix[, 3]
dim(X)
length(y)
beta_opt_func <- opt_beta_est(X, y)
print(beta_opt_func)
length(beta_opt_func)
# Optimization using L-BFGS-B
opt <- optim(par = beta_init, fn = log_likelihood, method = "L-BFGS-B")
return(opt$par)
opt$par
setwd("~/GitHub/Final_Project_Group1")
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "L-BFGS-B"  # optimization method
)
}
initial_beta <- function(X, y) {
solve(t(X)%*%X) %*% t(X)%*%y
}
# loss function function
# loss_func <- function(beta, X, y) {
#   p <- 1 / (1 + exp(-X %*% beta))
#   sum(-y * log(p) - (1 - y) * log(1 - p))
# }
# test loss
loss_func <- function(beta, X, y) {
p <- 1 / (1 + exp(-X %*% beta))
p <- pmin(pmax(p, 1e-15), 1 - 1e-15)  # Clip probabilities
sum(-y * log(p) - (1 - y) * log(1 - p))
}
# beta optimization function
estimate_beta <- function(X, y, beta_initial) {
optim(
par = beta_initial,
fn = loss_func,
X = X,
y = y,
method = "L-BFGS-B"  # optimization method
)
}
# calculate initial beta
beta_init <- initial_beta(X, y)
# testing final function
beta_opt <- opt_beta_est(X = X, y = y)
# Predict probabilities and calculate metrics
y_pred <- 1 / (1 + exp(-X %*% beta_opt_func))  # use design matrix with intercept
# Calculate metrics
metrics <- confusion_metrics(y, y_pred, cutoff = 0.5)
# Print confusion matrix metrics
print(metrics)
